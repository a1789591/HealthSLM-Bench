<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>HealthSLM-Bench</title>
</head>

<body style="max-width: 800px; margin: auto; padding: 40px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; line-height: 1.6;">

<h1 style="margin-bottom: 6px;">HealthSLM-Bench</h1>
<h2 style="margin-top: 0; font-weight: 500; color: #374151;">
  Benchmarking Small Language Models for Mobile and Wearable Healthcare Monitoring
</h2>

<p style="font-style: italic; font-size: 1.05rem;">
  Xin Wang, Ting Dang, Xinyu Zhang, Vassilis Kostakos, Michael J. Witbrock, Hong Jia
</p>

<p style="color: #555;">
üìÖ <strong>Published:</strong> 12 Oct 2025  
&ensp;¬∑&ensp; <strong>Last Modified:</strong> 13 Nov 2025  
<br>
üìÅ <strong>GenAI4Health 2025 Poster</strong>
</p>

<p style="font-size: 1.05rem;">
üíª <a href="https://github.com/a1789591/HealthSLM-Bench" target="_blank">Code</a>  
&ensp;¬∑&ensp; üìÑ Paper (coming soon)
</p>

<hr style="margin: 30px 0;">

<h2>TL;DR</h2>
<p>
This paper benchmarks Small Language Models (SLMs) for mobile health applications, demonstrating
efficient, privacy-preserving predictions on wearable devices, with performance comparable to
larger language models (LLMs) in health task predictions.
</p>

<h2>Abstract</h2>
<p>
Mobile and wearable healthcare monitoring play a vital role in facilitating timely interventions,
managing chronic health conditions, and ultimately improving individuals‚Äô quality of life.
Previous studies on large language models (LLMs) have highlighted their impressive generalization
abilities and effectiveness in healthcare prediction tasks. However, most LLM-based healthcare
solutions are cloud-based, raising significant privacy concerns and increasing memory usage and latency.
</p>
<p>
To address these challenges, there is growing interest in compact models, Small Language Models (SLMs),
which run efficiently on mobile and wearable devices. We systematically benchmarked SLMs on health
prediction tasks using zero-shot, few-shot, and instruction-tuning settings, and deployed the best
fine-tuned SLMs on mobile hardware to evaluate real-world performance.
</p>
<p>
Our results show that SLMs can achieve performance comparable to LLMs while offering substantial
gains in efficiency‚Äîup to 17√ó lower latency and 16√ó faster inference on mobile platforms. Challenges
remain in handling class imbalance and few-shot scenarios, highlighting SLMs as a promising solution
for next-generation, privacy-preserving healthcare monitoring.
</p>

<h2>Keywords</h2>
<ul>
  <li>Small Language Models (SLMs)</li>
  <li>Mobile Health</li>
  <li>On-Device LLMs</li>
  <li>Wearable Computing</li>
</ul>

<hr style="margin: 40px 0;">

<p style="color: #777; font-size: 0.9rem;">
This page provides a minimal project overview for <strong>HealthSLM-Bench</strong>.  
Links to the final paper, datasets, and models will be added when available.
</p>

</body>
</html>
