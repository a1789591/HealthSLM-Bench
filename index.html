<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>HealthSLM-Bench</title>
<style>
    body {
        margin: 0;
        padding: 0;
        background: #f2f4f7; /* Ê∑°ÁÅ∞ËÉåÊôØ */
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    }
    .container {
        max-width: 900px;
        margin: 40px auto;
        background: white;
        padding: 40px 50px;
        border-radius: 16px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
    }
    h1 {
        margin-bottom: 4px;
    }
    h2 {
        margin-top: 30px;
    }
    .subtitle {
        font-size: 1.2rem;
        color: #374151;
        margin-bottom: 12px;
    }
    .authors {
        font-style: italic;
        color: #444;
        margin-bottom: 10px;
    }
    .meta {
        color: #555;
        font-size: 0.95rem;
        margin-bottom: 16px;
    }
    a { color: #1d4ed8; text-decoration: none; }
    a:hover { text-decoration: underline; }
    .image-box {
        margin: 30px 0;
        text-align: center;
    }
    .image-box img {
        width: 100%;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.06);
    }
</style>
</head>

<body>

<div class="container">

<h1>HealthSLM-Bench</h1>
<div class="subtitle">Benchmarking Small Language Models for Mobile and Wearable Healthcare Monitoring</div>

<div class="authors">
Xin Wang, Ting Dang, Xinyu Zhang, Vassilis Kostakos, Michael J. Witbrock, Hong Jia
</div>

<div class="meta">
üìÖ <strong>Published:</strong> 12 Oct 2025  
&ensp;¬∑&ensp; <strong>Last Modified:</strong> 13 Nov 2025  
<br>
üìÅ <strong>GenAI4Health 2025 Poster</strong>
</div>

<p>
üîó <a href="https://github.com/a1789591/HealthSLM-Bench">Code</a>  
&ensp;¬∑&ensp; üìÑ Paper (coming soon)
</p>

<hr style="margin: 30px 0;">

<h2>TL;DR</h2>
<p>
This paper benchmarks Small Language Models (SLMs) for mobile health applications,
demonstrating efficient, privacy-preserving predictions on wearable devices,
with performance comparable to larger language models (LLMs) in health task predictions.
</p>

<h2>Abstract</h2>
<p>
Mobile and wearable healthcare monitoring play a vital role in facilitating timely interventions,
managing chronic health conditions, and ultimately improving individuals‚Äô quality of life.
Previous studies on large language models (LLMs) have highlighted their impressive generalization
abilities and effectiveness in healthcare prediction tasks. However, most LLM-based healthcare
solutions are cloud-based, raising significant privacy concerns and increasing memory usage
and latency.
</p>
<p>
To address these challenges, compact Small Language Models (SLMs) have emerged as an alternative.
We systematically benchmarked SLMs on health prediction tasks using zero-shot, few-shot,
and instruction-tuning settings, and deployed the best fine-tuned SLMs on mobile devices
to evaluate real-world performance.
</p>
<p>
Our results show that SLMs can achieve performance comparable to LLMs while offering substantial
gains in efficiency‚Äîup to 17√ó lower latency and 16√ó faster inference on mobile platforms.
Challenges remain in handling class imbalance and few-shot scenarios, highlighting SLMs
as a promising solution for next-generation, privacy-preserving healthcare monitoring.
</p>

<h2>Overview</h2>

<div class="image-box">
    <!-- Âú®ËøôÈáåÊîæ‰Ω†ÁöÑ overview ÂõæÔºàÂÉè Menta Âõæ‰∏ÄÊ†∑Ôºâ -->
    <img src="overview.png" alt="Overview figure (replace with your own)">
</div>

<p style="color:#666; font-size:0.9rem;">
(Replace <code>overview.png</code> with your own figure.  
Upload your image into the repository ‚Üí use its raw URL here.)
</p>

</div>

</body>
</html>
